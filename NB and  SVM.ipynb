{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FEATURE EXTRACTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from textblob import TextBlob\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>talk ilandthere surprisingly lot people like i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>yes suicide haram makingsomeones life miserabl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>stressed depressed go need somebody talk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>always learn strong alone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>catarllna add another</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>see bass canyon lost land fill survey thingy v...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>underside worldof course stupid bles iiiii</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>working mall brain filled poison edg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>within new york state park police alone office...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>I literally tired</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text\n",
       "0  talk ilandthere surprisingly lot people like i...\n",
       "1  yes suicide haram makingsomeones life miserabl...\n",
       "2           stressed depressed go need somebody talk\n",
       "3                          always learn strong alone\n",
       "4                              catarllna add another\n",
       "5  see bass canyon lost land fill survey thingy v...\n",
       "6         underside worldof course stupid bles iiiii\n",
       "7               working mall brain filled poison edg\n",
       "8  within new york state park police alone office...\n",
       "9                                  I literally tired"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = pd.read_csv(\"Processed_tweets.csv\")\n",
    "d = d.drop([\"Unnamed: 0\"],axis=1)\n",
    "d.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "d.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "d.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 6735 entries, 0 to 6918\n",
      "Data columns (total 1 columns):\n",
      "Text    6735 non-null object\n",
      "dtypes: object(1)\n",
      "memory usage: 105.2+ KB\n"
     ]
    }
   ],
   "source": [
    "d.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = len(d)\n",
    "d[\"Sentiment\"]=[None for i in range(n)]\n",
    "for i in range(n):\n",
    "    \n",
    "    s = TextBlob(d[\"Text\"].iloc[i]).sentiment\n",
    "    if(s[0]>=0):\n",
    "        d[\"Sentiment\"].iloc[i] = 0\n",
    "    else:\n",
    "        d[\"Sentiment\"].iloc[i] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4519, 2216)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(d[d[\"Sentiment\"]==0]), len(d[d[\"Sentiment\"]==1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "no = len(d[d[\"Sentiment\"]==1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = d[d[\"Sentiment\"]==0][:no]\n",
    "s = d[d[\"Sentiment\"]==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4432"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.concat([s,t],ignore_index=\"True\")\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODEL DEVELOPMENT AND EVALUATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting into Train and Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x= df[\"Text\"]\n",
    "y = df[\"Sentiment\"].astype(\"int\")\n",
    "x_train,x_test, y_train, y_test = train_test_split(x,y,test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer(ngram_range=(1,3))\n",
    "tf = TfidfVectorizer(ngram_range=(1,3))\n",
    "x1 = cv.fit_transform(x_train)\n",
    "x2 = tf.fit_transform(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "accuracy = {}\n",
    "model = {}\n",
    "vectorizer = {\"CountVectorizer\":cv,\"TfidfVectorizer\":tf}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "classifier=svm.SVC()\n",
    "classifier.fit(x1,y_train)\n",
    "y_predict1=classifier.predict(cv.transform(x_test))\n",
    "k = \"Support Vector Machine with CountVectorizer\"\n",
    "model[k]=classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Support Vector Machine with CountVectorizer\n",
      "Accuracy:  0.7813\n",
      "Recall  : 0.6112\n"
     ]
    }
   ],
   "source": [
    "b1=metrics.accuracy_score(y_test, y_predict1)\n",
    "recall = metrics.recall_score(y_test, y_predict1)\n",
    "accuracy[k] = float(\"{0:.4f}\".format(b1))\n",
    "print(k)\n",
    "print(\"Accuracy: \",accuracy[k])\n",
    "print(\"Recall  : {0:.4f}\".format(recall))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier=svm.SVC()\n",
    "classifier.fit(x2,y_train)\n",
    "y_predict2=classifier.predict(tf.transform(x_test))\n",
    "k = \"Support Vector Machine with TfidfVectorizer\"\n",
    "model[k]=classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Support Vector Machine with TfidfVectorizer\n",
      "Accuracy:  0.8196\n",
      "Recall  : 0.7365\n"
     ]
    }
   ],
   "source": [
    "b2=metrics.accuracy_score(y_test, y_predict2)\n",
    "recall = metrics.recall_score(y_test, y_predict2)\n",
    "accuracy[k] = float(\"{0:.4f}\".format(b2))\n",
    "print(k)\n",
    "print(\"Accuracy: \",accuracy[k])\n",
    "print(\"Recall  : {0:.4f}\".format(recall))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multinomial Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "nb = MultinomialNB()\n",
    "nb.fit(x1,y_train)\n",
    "y_predict3=classifier.predict(cv.transform(x_test))\n",
    "k = \"Multinomial Naive Bayes with CountVectorizer\"\n",
    "model[k]=nb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multinomial Naive Bayes with CountVectorizer\n",
      "Accuracy:  0.5524\n",
      "Recall  : 0.1469\n"
     ]
    }
   ],
   "source": [
    "b3=metrics.accuracy_score(y_test, y_predict3)\n",
    "recall = metrics.recall_score(y_test, y_predict3)\n",
    "accuracy[k] = float(\"{0:.4f}\".format(b3))\n",
    "print(k)\n",
    "print(\"Accuracy: \",accuracy[k])\n",
    "print(\"Recall  : {0:.4f}\".format(recall))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb = MultinomialNB()\n",
    "nb.fit(x2,y_train)\n",
    "y_predict4=classifier.predict(tf.transform(x_test))\n",
    "k = \"Multinomial Naive Bayes with TfidfVectorizer\"\n",
    "model[k]=nb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multinomial Naive Bayes with TfidfVectorizer\n",
      "Accuracy:  0.8196\n",
      "Recall  : 0.7365\n"
     ]
    }
   ],
   "source": [
    "b4=metrics.accuracy_score(y_test,y_predict4)\n",
    "recall = metrics.recall_score(y_test, y_predict4)\n",
    "accuracy[k] = float(\"{0:.4f}\".format(b4))\n",
    "print(k)\n",
    "print(\"Accuracy: \",accuracy[k])\n",
    "print(\"Recall  : {0:.4f}\".format(recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Multinomial Naive Bayes with CountVectorizer</th>\n",
       "      <td>0.5524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Multinomial Naive Bayes with TfidfVectorizer</th>\n",
       "      <td>0.8196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Support Vector Machine with CountVectorizer</th>\n",
       "      <td>0.7813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Support Vector Machine with TfidfVectorizer</th>\n",
       "      <td>0.8196</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Accuracy\n",
       "Multinomial Naive Bayes with CountVectorizer    0.5524\n",
       "Multinomial Naive Bayes with TfidfVectorizer    0.8196\n",
       "Support Vector Machine with CountVectorizer     0.7813\n",
       "Support Vector Machine with TfidfVectorizer     0.8196"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(accuracy)\n",
    "ad = pd.DataFrame({\"Accuracy\":accuracy})\n",
    "ad"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
